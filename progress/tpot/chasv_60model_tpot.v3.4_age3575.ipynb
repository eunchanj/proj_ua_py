{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chasv_60model_tpot.v3.4, age 35-75\n",
    "split 7:3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danssa/anaconda3/envs/rapids-0.17/lib/python3.8/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.\n",
      "  warnings.warn(\"Warning: optional dependency `torch` is not available. - skipping import of NN models.\")\n"
     ]
    }
   ],
   "source": [
    "SEED = 0\n",
    "cores = 16\n",
    "from numpy.random import seed\n",
    "seed(SEED)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tpot import TPOTClassifier\n",
    "from sklearn.preprocessing import KBinsDiscretizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eGFR_ab</th>\n",
       "      <th>eGFR_ckd</th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>he_uph</th>\n",
       "      <th>he_unitr</th>\n",
       "      <th>he_usg</th>\n",
       "      <th>he_upro</th>\n",
       "      <th>he_uglu</th>\n",
       "      <th>he_uket</th>\n",
       "      <th>he_ubil</th>\n",
       "      <th>he_ubld</th>\n",
       "      <th>he_uro</th>\n",
       "      <th>leucocyte</th>\n",
       "      <th>dm</th>\n",
       "      <th>htn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>154841.000000</td>\n",
       "      <td>154841.000000</td>\n",
       "      <td>154841.000000</td>\n",
       "      <td>154841.000000</td>\n",
       "      <td>154841.000000</td>\n",
       "      <td>154841.000000</td>\n",
       "      <td>154841.000000</td>\n",
       "      <td>154841.000000</td>\n",
       "      <td>154841.000000</td>\n",
       "      <td>154841.000000</td>\n",
       "      <td>154841.000000</td>\n",
       "      <td>154841.000000</td>\n",
       "      <td>154841.000000</td>\n",
       "      <td>154841.000000</td>\n",
       "      <td>154841.000000</td>\n",
       "      <td>154841.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.060262</td>\n",
       "      <td>90.906962</td>\n",
       "      <td>0.458206</td>\n",
       "      <td>50.713377</td>\n",
       "      <td>6.156848</td>\n",
       "      <td>0.018161</td>\n",
       "      <td>1.018472</td>\n",
       "      <td>0.306405</td>\n",
       "      <td>0.257270</td>\n",
       "      <td>0.173526</td>\n",
       "      <td>0.035314</td>\n",
       "      <td>0.736995</td>\n",
       "      <td>0.154720</td>\n",
       "      <td>0.454744</td>\n",
       "      <td>0.033066</td>\n",
       "      <td>0.050432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.237972</td>\n",
       "      <td>19.873652</td>\n",
       "      <td>0.498252</td>\n",
       "      <td>11.012321</td>\n",
       "      <td>0.829076</td>\n",
       "      <td>0.133532</td>\n",
       "      <td>0.007956</td>\n",
       "      <td>0.748006</td>\n",
       "      <td>0.937064</td>\n",
       "      <td>0.605177</td>\n",
       "      <td>0.308274</td>\n",
       "      <td>1.224300</td>\n",
       "      <td>0.524733</td>\n",
       "      <td>0.970793</td>\n",
       "      <td>0.178810</td>\n",
       "      <td>0.218836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.704754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.005000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>79.117990</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>93.158990</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.020000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>105.837633</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.025000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>257.176000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.030000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             eGFR_ab       eGFR_ckd           male            age  \\\n",
       "count  154841.000000  154841.000000  154841.000000  154841.000000   \n",
       "mean        0.060262      90.906962       0.458206      50.713377   \n",
       "std         0.237972      19.873652       0.498252      11.012321   \n",
       "min         0.000000       1.704754       0.000000      35.000000   \n",
       "25%         0.000000      79.117990       0.000000      41.000000   \n",
       "50%         0.000000      93.158990       0.000000      49.000000   \n",
       "75%         0.000000     105.837633       1.000000      59.000000   \n",
       "max         1.000000     257.176000       1.000000      74.000000   \n",
       "\n",
       "              he_uph       he_unitr         he_usg        he_upro  \\\n",
       "count  154841.000000  154841.000000  154841.000000  154841.000000   \n",
       "mean        6.156848       0.018161       1.018472       0.306405   \n",
       "std         0.829076       0.133532       0.007956       0.748006   \n",
       "min         5.000000       0.000000       1.005000       0.000000   \n",
       "25%         5.500000       0.000000       1.010000       0.000000   \n",
       "50%         6.000000       0.000000       1.020000       0.000000   \n",
       "75%         7.000000       0.000000       1.025000       0.000000   \n",
       "max         9.000000       1.000000       1.030000       5.000000   \n",
       "\n",
       "             he_uglu        he_uket        he_ubil        he_ubld  \\\n",
       "count  154841.000000  154841.000000  154841.000000  154841.000000   \n",
       "mean        0.257270       0.173526       0.035314       0.736995   \n",
       "std         0.937064       0.605177       0.308274       1.224300   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       1.000000   \n",
       "max         5.000000       5.000000       4.000000       5.000000   \n",
       "\n",
       "              he_uro      leucocyte             dm            htn  \n",
       "count  154841.000000  154841.000000  154841.000000  154841.000000  \n",
       "mean        0.154720       0.454744       0.033066       0.050432  \n",
       "std         0.524733       0.970793       0.178810       0.218836  \n",
       "min         0.000000       0.000000       0.000000       0.000000  \n",
       "25%         0.000000       0.000000       0.000000       0.000000  \n",
       "50%         0.000000       0.000000       0.000000       0.000000  \n",
       "75%         0.000000       0.000000       0.000000       0.000000  \n",
       "max         4.000000       4.000000       1.000000       1.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/home/danssa/proj_ua/data/chasv_development.v1.csv\", dtype={'id':np.str}).query('age>=35&age<75')\n",
    "df2 = df.loc[df['from']!=\"knhanes\"]\n",
    "df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edges :  [35.         51.66352511 63.73024576 74.        ]\n",
      "age0_edge: 51.663525113906786 \n",
      "age1_edge: 63.73024575557389 \n",
      "age2_edge: 74.0\n",
      "age group:\n",
      " 0    1443\n",
      "1    2751\n",
      "2    5137\n",
      "Name: level, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#3group age split  \n",
    "\n",
    "##step 1 finding edge value\n",
    "abnormal_disc = df2.query('eGFR_ab==1').loc[:,'age']\n",
    "abnormal_disc = pd.DataFrame(abnormal_disc)\n",
    "\n",
    "est = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='kmeans')\n",
    "est.fit(abnormal_disc)\n",
    "\n",
    "ab_disc = est.transform(abnormal_disc).astype('float')\n",
    "print(\"edges : \", est.bin_edges_[0])\n",
    "\n",
    "age0_edge = est.bin_edges_[0][1]\n",
    "age1_edge = est.bin_edges_[0][2]\n",
    "age2_edge = est.bin_edges_[0][3]\n",
    "print('age0_edge:', age0_edge, '\\nage1_edge:', age1_edge, '\\nage2_edge:', age2_edge)\n",
    "\n",
    "abnormal_disc['level'] = abnormal_disc.apply(lambda x : 0 if x['age']<age0_edge else 1 if x['age']<age1_edge else 2, axis=1)\n",
    "print('age group:\\n',abnormal_disc['level'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    86910\n",
      "1    42377\n",
      "2    25554\n",
      "Name: level, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "##make 3group by age\n",
    "\n",
    "df3 = df2.copy()\n",
    "\n",
    "df3['level'] = df3.apply(lambda x : 0 if x['age']<age0_edge else 1 if x['age']<age1_edge else 2, axis=1)\n",
    "print(df3['level'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total cases = 86910\n",
      "total abnormal function of kidney = 1443\n",
      "train0 : 1010 test0 : 433\n"
     ]
    }
   ],
   "source": [
    "##age0 group\n",
    "X_age0 = df3[df3['level']==0]\n",
    "y_age0 = X_age0['eGFR_ab'].astype(\"int64\")\n",
    "\n",
    "print(\"total cases = %d\" %X_age0.shape[0])\n",
    "print(\"total abnormal function of kidney = %d\" %sum(y_age0))\n",
    "\n",
    "X_train0, X_test0, y_train0, y_test0 = train_test_split(X_age0, y_age0, test_size=0.3, stratify=y_age0, random_state=SEED)\n",
    "print(\"train0 : %d\" % sum(y_train0), \"test0 : %d\" % sum(y_test0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total cases = 42377\n",
      "total abnormal function of kidney = 2751\n",
      "train1 : 1926 test0 : 825\n"
     ]
    }
   ],
   "source": [
    "##age1 group\n",
    "X_age1 = df3[df3['level']==1]\n",
    "y_age1 = X_age1['eGFR_ab']\n",
    "\n",
    "print(\"total cases = %d\" %X_age1.shape[0])\n",
    "print(\"total abnormal function of kidney = %d\" %sum(y_age1))\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X_age1, y_age1, test_size=0.3, stratify=y_age1, random_state=SEED)\n",
    "print(\"train1 : %d\" % sum(y_train1), \"test0 : %d\" % sum(y_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total cases = 25554\n",
      "total abnormal function of kidney = 5137\n",
      "train2 : 3596 test2 : 1541\n"
     ]
    }
   ],
   "source": [
    "##age2 group\n",
    "X_age2 = df3[df3['level']==2]\n",
    "y_age2 = X_age2['eGFR_ab']\n",
    "\n",
    "print(\"total cases = %d\" %X_age2.shape[0])\n",
    "print(\"total abnormal function of kidney = %d\" %sum(y_age2))\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_age2, y_age2, test_size=0.3, stratify=y_age2, random_state=SEED)\n",
    "print(\"train2 : %d\" % sum(y_train2), \"test2 : %d\" % sum(y_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total cases = 154841\n",
      "total abnormal function of kidney = 9331\n"
     ]
    }
   ],
   "source": [
    "##concat both trainset and testset\n",
    "X_train = pd.concat([X_train0, X_train1, X_train2])\n",
    "y_train = pd.concat([y_train0, y_train1, y_train2])\n",
    "\n",
    "X_test = pd.concat([X_test0, X_test1, X_test2])\n",
    "y_test = pd.concat([y_test0, y_test1, y_test2])\n",
    "\n",
    "print(\"total cases = %d\" % (X_train.shape[0] + X_test.shape[0]))\n",
    "print(\"total abnormal function of kidney = %d\" % (sum(y_train) + sum(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108387 train cases, 12 variables\n",
      "46454 test cases\n"
     ]
    }
   ],
   "source": [
    "X_train_features = X_train.loc[:, 'male':'leucocyte']\n",
    "\n",
    "print('%d train cases, %d variables' % (X_train_features.shape[0], X_train_features.shape[1]))\n",
    "print('%d test cases'%X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>he_uph</th>\n",
       "      <th>he_unitr</th>\n",
       "      <th>he_usg</th>\n",
       "      <th>he_upro</th>\n",
       "      <th>he_uglu</th>\n",
       "      <th>he_uket</th>\n",
       "      <th>he_ubil</th>\n",
       "      <th>he_ubld</th>\n",
       "      <th>he_uro</th>\n",
       "      <th>leucocyte</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>108387.000000</td>\n",
       "      <td>1.083870e+05</td>\n",
       "      <td>1.083870e+05</td>\n",
       "      <td>108387.000000</td>\n",
       "      <td>1.083870e+05</td>\n",
       "      <td>108387.000000</td>\n",
       "      <td>108387.000000</td>\n",
       "      <td>108387.000000</td>\n",
       "      <td>108387.000000</td>\n",
       "      <td>108387.000000</td>\n",
       "      <td>108387.000000</td>\n",
       "      <td>108387.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.459483</td>\n",
       "      <td>-1.762148e-16</td>\n",
       "      <td>2.055839e-16</td>\n",
       "      <td>0.018129</td>\n",
       "      <td>-2.518645e-14</td>\n",
       "      <td>0.303828</td>\n",
       "      <td>0.254809</td>\n",
       "      <td>0.171866</td>\n",
       "      <td>0.035124</td>\n",
       "      <td>0.735596</td>\n",
       "      <td>0.154954</td>\n",
       "      <td>0.452942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.498358</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>0.133420</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>0.745698</td>\n",
       "      <td>0.931188</td>\n",
       "      <td>0.600703</td>\n",
       "      <td>0.305977</td>\n",
       "      <td>1.221780</td>\n",
       "      <td>0.525620</td>\n",
       "      <td>0.968983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.428323e+00</td>\n",
       "      <td>-1.398607e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.693318e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-8.829833e-01</td>\n",
       "      <td>-7.948687e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.064578e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.558632e-01</td>\n",
       "      <td>-1.911305e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.929025e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.530369e-01</td>\n",
       "      <td>1.016346e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.216426e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.116387e+00</td>\n",
       "      <td>3.431298e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.450383e+00</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                male           age        he_uph       he_unitr        he_usg  \\\n",
       "count  108387.000000  1.083870e+05  1.083870e+05  108387.000000  1.083870e+05   \n",
       "mean        0.459483 -1.762148e-16  2.055839e-16       0.018129 -2.518645e-14   \n",
       "std         0.498358  1.000005e+00  1.000005e+00       0.133420  1.000005e+00   \n",
       "min         0.000000 -1.428323e+00 -1.398607e+00       0.000000 -1.693318e+00   \n",
       "25%         0.000000 -8.829833e-01 -7.948687e-01       0.000000 -1.064578e+00   \n",
       "50%         0.000000 -1.558632e-01 -1.911305e-01       0.000000  1.929025e-01   \n",
       "75%         1.000000  7.530369e-01  1.016346e+00       0.000000  8.216426e-01   \n",
       "max         1.000000  2.116387e+00  3.431298e+00       1.000000  1.450383e+00   \n",
       "\n",
       "             he_upro        he_uglu        he_uket        he_ubil  \\\n",
       "count  108387.000000  108387.000000  108387.000000  108387.000000   \n",
       "mean        0.303828       0.254809       0.171866       0.035124   \n",
       "std         0.745698       0.931188       0.600703       0.305977   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         5.000000       5.000000       5.000000       4.000000   \n",
       "\n",
       "             he_ubld         he_uro      leucocyte  \n",
       "count  108387.000000  108387.000000  108387.000000  \n",
       "mean        0.735596       0.154954       0.452942  \n",
       "std         1.221780       0.525620       0.968983  \n",
       "min         0.000000       0.000000       0.000000  \n",
       "25%         0.000000       0.000000       0.000000  \n",
       "50%         0.000000       0.000000       0.000000  \n",
       "75%         1.000000       0.000000       0.000000  \n",
       "max         5.000000       4.000000       4.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#standardization\n",
    "\n",
    "scaler = StandardScaler()\n",
    "std_cols=['age','he_uph','he_usg']\n",
    "std_df=X_train_features[std_cols]\n",
    "\n",
    "X_train_features[std_cols]=scaler.fit_transform(std_df)\n",
    "X_train_features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "counter = Counter(y_train)\n",
    "estimate = round(counter[0]/counter[1])\n",
    "step = round((estimate - 1)/3)\n",
    "estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danssa/anaconda3/envs/rapids-0.17/lib/python3.8/site-packages/distributed/node.py:151: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 39527 instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#https://dask-cuda.readthedocs.io/en/latest/quickstart.html\n",
    "\n",
    "from dask_cuda import LocalCUDACluster\n",
    "from dask.distributed import Client\n",
    "\n",
    "# Create a Dask Cluster with one worker per GPU\n",
    "cluster = LocalCUDACluster()\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 operators have been imported by TPOT.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Version 0.11.6.post3 of tpot is outdated. Version 0.11.7 was released Wednesday January 06, 2021.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/10100 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8435419705563717\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=0.4, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=5, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=1, XGBClassifier__reg_lambda=2, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=1.0, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "\n",
      "Generation 2 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8435419705563717\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=0.4, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=5, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=1, XGBClassifier__reg_lambda=2, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=1.0, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "\n",
      "Generation 3 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8435419705563717\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=0.4, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=5, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=1, XGBClassifier__reg_lambda=2, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=1.0, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "\n",
      "Generation 4 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8435419705563717\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=0.4, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=5, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=1, XGBClassifier__reg_lambda=2, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=1.0, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "\n",
      "Generation 5 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8435419705563717\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=0.4, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=5, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=1, XGBClassifier__reg_lambda=2, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=1.0, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "\n",
      "Generation 6 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8435419705563717\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=0.4, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=5, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=1, XGBClassifier__reg_lambda=2, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=1.0, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "\n",
      "Generation 7 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8435419705563717\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=0.4, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=5, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=1, XGBClassifier__reg_lambda=2, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=1.0, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 8 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8435419705563717\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=0.4, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=5, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=1, XGBClassifier__reg_lambda=2, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=1.0, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "\n",
      "Generation 9 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.843696750693427\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=0.4, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=5, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=1, XGBClassifier__reg_lambda=6, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=1.0, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 10 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8458223028801569\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=14, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.25, XGBClassifier__reg_lambda=2, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 11 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8460901285982908\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=14, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=2, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "\n",
      "Generation 12 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8460901285982908\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=14, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=2, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "\n",
      "Generation 13 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8463382977671889\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=14, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.25, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 14 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8463382977671889\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=14, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.25, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 15 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8463382977671889\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=14, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.25, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "\n",
      "Generation 16 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8463382977671889\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=14, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.25, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 17 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8463382977671889\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=14, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.25, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "\n",
      "Generation 18 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8463382977671889\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=14, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.25, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "\n",
      "Generation 19 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8463382977671889\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=14, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.25, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "\n",
      "Generation 20 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464386168749467\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.4000000000000001, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=6, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "\n",
      "Generation 21 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464386168749467\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.4000000000000001, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=6, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "\n",
      "Generation 22 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464386168749467\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.4000000000000001, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=6, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 23 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464386168749467\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.4000000000000001, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=6, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 24 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464386168749467\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.4000000000000001, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=6, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "\n",
      "Generation 25 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464386168749467\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.4000000000000001, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=6, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 26 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 27 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 28 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 29 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 30 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 31 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 32 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 33 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 34 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 35 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 36 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 37 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 38 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 39 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 40 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 41 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 42 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 43 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 44 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 45 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 46 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 47 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 48 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 49 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 50 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 51 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 52 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 53 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 54 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 55 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 56 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 57 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 58 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 59 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 60 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 61 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 62 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 63 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 64 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 65 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 66 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 67 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 68 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 69 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 70 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 71 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 72 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 73 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 74 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 75 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 76 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 77 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 78 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 79 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 80 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 81 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 82 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 83 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 84 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 85 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 86 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 87 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 88 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 89 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 90 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 91 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 92 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 93 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 94 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 95 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 96 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 97 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 98 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 99 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 100 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8464466360649249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=1.0000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=16, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n"
     ]
    }
   ],
   "source": [
    "classifier_config_dict = {\n",
    "\n",
    "    # xgboost tree method = gpu hist\n",
    "    \n",
    "    'xgboost.XGBClassifier': {\n",
    "        'n_estimators': [100, 250 ,500, 750, 1000],\n",
    "        'learning_rate': [1e-2, 1e-1, 0.3],\n",
    "        'max_depth': range(2, 11),\n",
    "        'min_child_weight': range(1, 21),\n",
    "        'gamma':np.arange(0, 2.01, 0.2),\n",
    "        'subsample': np.arange(0.2, 1.01, 0.2),\n",
    "        'colsample_bytree': np.arange(0.4,1.01,0.2),\n",
    "        \"reg_alpha\": [0, 0.25, 0.5, 0.75, 1],\n",
    "        \"reg_lambda\": [1, 2, 4, 6, 8],\n",
    "        'scale_pos_weight': [estimate],\n",
    "        'objective': ['binary:logistic'],\n",
    "        'tree_method' : ['gpu_hist'],\n",
    "        'n_jobs': [1],\n",
    "        'verbosity': [0]\n",
    "    },\n",
    "\n",
    "}\n",
    "\n",
    "tpot = TPOTClassifier(scoring=\"roc_auc\",\n",
    "                      cv=5,\n",
    "                      random_state=SEED,\n",
    "                      n_jobs=4,\n",
    "                      verbosity=3,\n",
    "                      generations=100,\n",
    "                      population_size=100,\n",
    "                      use_dask=True,\n",
    "                      warm_start=False,\n",
    "                      config_dict=classifier_config_dict,\n",
    "                      template='Classifier')\n",
    "\n",
    "training_features=X_train_features.copy(deep=True)\n",
    "tpot.fit(training_features, y_train)\n",
    "\n",
    "tpot.export('/home/danssa/proj_ua/progress/CHA+SV*/60model/chasv_60model.v3.4_age3575.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot.export('/home/danssa/proj_ua/progress/CHA+SV*/60model/chasv_60model.v3.4_age3575.py')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multi_gpu",
   "language": "python",
   "name": "rapids-0.17"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
