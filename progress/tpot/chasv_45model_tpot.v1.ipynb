{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chasv_45model_tpot.v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danssa/anaconda3/envs/rapids-0.17/lib/python3.8/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.\n",
      "  warnings.warn(\"Warning: optional dependency `torch` is not available. - skipping import of NN models.\")\n"
     ]
    }
   ],
   "source": [
    "SEED = 0\n",
    "cores = 16\n",
    "from numpy.random import seed\n",
    "seed(SEED)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tpot import TPOTClassifier\n",
    "from sklearn.preprocessing import KBinsDiscretizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-d081faf5f640>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['eGFR_ab45'] = np.where(df2['eGFR_ckd']<45,1,0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eGFR_ab</th>\n",
       "      <th>eGFR_ckd</th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>he_uph</th>\n",
       "      <th>he_unitr</th>\n",
       "      <th>he_usg</th>\n",
       "      <th>he_upro</th>\n",
       "      <th>he_uglu</th>\n",
       "      <th>he_uket</th>\n",
       "      <th>he_ubil</th>\n",
       "      <th>he_ubld</th>\n",
       "      <th>he_uro</th>\n",
       "      <th>leucocyte</th>\n",
       "      <th>dm</th>\n",
       "      <th>htn</th>\n",
       "      <th>eGFR_ab45</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>220020.000000</td>\n",
       "      <td>220020.000000</td>\n",
       "      <td>220020.000000</td>\n",
       "      <td>220020.000000</td>\n",
       "      <td>220020.000000</td>\n",
       "      <td>220020.000000</td>\n",
       "      <td>220020.000000</td>\n",
       "      <td>220020.000000</td>\n",
       "      <td>220020.000000</td>\n",
       "      <td>220020.000000</td>\n",
       "      <td>220020.000000</td>\n",
       "      <td>220020.000000</td>\n",
       "      <td>220020.000000</td>\n",
       "      <td>220020.000000</td>\n",
       "      <td>220020.000000</td>\n",
       "      <td>220020.000000</td>\n",
       "      <td>220020.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.067598</td>\n",
       "      <td>93.719380</td>\n",
       "      <td>0.428929</td>\n",
       "      <td>47.179829</td>\n",
       "      <td>6.183206</td>\n",
       "      <td>0.020280</td>\n",
       "      <td>1.018628</td>\n",
       "      <td>0.331024</td>\n",
       "      <td>0.234011</td>\n",
       "      <td>0.205590</td>\n",
       "      <td>0.039356</td>\n",
       "      <td>0.757068</td>\n",
       "      <td>0.168417</td>\n",
       "      <td>0.516135</td>\n",
       "      <td>0.025325</td>\n",
       "      <td>0.039046</td>\n",
       "      <td>0.029161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.251056</td>\n",
       "      <td>22.147902</td>\n",
       "      <td>0.494924</td>\n",
       "      <td>15.570474</td>\n",
       "      <td>0.824044</td>\n",
       "      <td>0.140957</td>\n",
       "      <td>0.007915</td>\n",
       "      <td>0.769946</td>\n",
       "      <td>0.888690</td>\n",
       "      <td>0.669646</td>\n",
       "      <td>0.324305</td>\n",
       "      <td>1.252923</td>\n",
       "      <td>0.560018</td>\n",
       "      <td>1.024153</td>\n",
       "      <td>0.157111</td>\n",
       "      <td>0.193706</td>\n",
       "      <td>0.168258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.704754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.005000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>80.803010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>95.813740</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.020000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>110.264000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.025000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>257.176000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.030000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             eGFR_ab       eGFR_ckd           male            age  \\\n",
       "count  220020.000000  220020.000000  220020.000000  220020.000000   \n",
       "mean        0.067598      93.719380       0.428929      47.179829   \n",
       "std         0.251056      22.147902       0.494924      15.570474   \n",
       "min         0.000000       1.704754       0.000000      18.000000   \n",
       "25%         0.000000      80.803010       0.000000      35.000000   \n",
       "50%         0.000000      95.813740       0.000000      45.000000   \n",
       "75%         0.000000     110.264000       1.000000      58.000000   \n",
       "max         1.000000     257.176000       1.000000      95.000000   \n",
       "\n",
       "              he_uph       he_unitr         he_usg        he_upro  \\\n",
       "count  220020.000000  220020.000000  220020.000000  220020.000000   \n",
       "mean        6.183206       0.020280       1.018628       0.331024   \n",
       "std         0.824044       0.140957       0.007915       0.769946   \n",
       "min         5.000000       0.000000       1.005000       0.000000   \n",
       "25%         5.500000       0.000000       1.010000       0.000000   \n",
       "50%         6.000000       0.000000       1.020000       0.000000   \n",
       "75%         7.000000       0.000000       1.025000       0.000000   \n",
       "max         9.000000       1.000000       1.030000       5.000000   \n",
       "\n",
       "             he_uglu        he_uket        he_ubil        he_ubld  \\\n",
       "count  220020.000000  220020.000000  220020.000000  220020.000000   \n",
       "mean        0.234011       0.205590       0.039356       0.757068   \n",
       "std         0.888690       0.669646       0.324305       1.252923   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       1.000000   \n",
       "max         5.000000       5.000000       4.000000       5.000000   \n",
       "\n",
       "              he_uro      leucocyte             dm            htn  \\\n",
       "count  220020.000000  220020.000000  220020.000000  220020.000000   \n",
       "mean        0.168417       0.516135       0.025325       0.039046   \n",
       "std         0.560018       1.024153       0.157111       0.193706   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       1.000000       0.000000       0.000000   \n",
       "max         5.000000       4.000000       1.000000       1.000000   \n",
       "\n",
       "           eGFR_ab45  \n",
       "count  220020.000000  \n",
       "mean        0.029161  \n",
       "std         0.168258  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/home/danssa/proj_ua/data/chasv_development.v1.csv\", dtype={'id':np.str})\n",
    "df2 = df.loc[df['from']!=\"knhanes\"]\n",
    "df2['eGFR_ab45'] = np.where(df2['eGFR_ckd']<45,1,0)\n",
    "df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edges :  [18.         51.91420022 70.59121313 95.        ]\n",
      "age0_edge: 51.91420022170918 \n",
      "age1_edge: 70.59121313469142 \n",
      "age2_edge: 95.0\n",
      "age group:\n",
      " 0     839\n",
      "1    2288\n",
      "2    3289\n",
      "Name: level, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#3group age split  \n",
    "\n",
    "##step 1 finding edge value\n",
    "abnormal_disc = df2.query('eGFR_ab45==1').loc[:,'age']\n",
    "abnormal_disc = pd.DataFrame(abnormal_disc)\n",
    "\n",
    "est = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='kmeans')\n",
    "est.fit(abnormal_disc)\n",
    "\n",
    "ab_disc = est.transform(abnormal_disc).astype('float')\n",
    "print(\"edges : \", est.bin_edges_[0])\n",
    "\n",
    "age0_edge = est.bin_edges_[0][1]\n",
    "age1_edge = est.bin_edges_[0][2]\n",
    "age2_edge = est.bin_edges_[0][3]\n",
    "print('age0_edge:', age0_edge, '\\nage1_edge:', age1_edge, '\\nage2_edge:', age2_edge)\n",
    "\n",
    "abnormal_disc['level'] = abnormal_disc.apply(lambda x : 0 if x['age']<age0_edge else 1 if x['age']<age1_edge else 2, axis=1)\n",
    "print('age group:\\n',abnormal_disc['level'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    139225\n",
      "1     60292\n",
      "2     20503\n",
      "Name: level, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "##make 3group by age\n",
    "\n",
    "df3 = df2.copy()\n",
    "\n",
    "df3['level'] = df3.apply(lambda x : 0 if x['age']<age0_edge else 1 if x['age']<age1_edge else 2, axis=1)\n",
    "print(df3['level'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total cases = 139225\n",
      "total abnormal function of kidney = 839\n",
      "train0 : 671 test0 : 168\n"
     ]
    }
   ],
   "source": [
    "##age0 group\n",
    "X_age0 = df3[df3['level']==0]\n",
    "y_age0 = X_age0['eGFR_ab45'].astype(\"int64\")\n",
    "\n",
    "print(\"total cases = %d\" %X_age0.shape[0])\n",
    "print(\"total abnormal function of kidney = %d\" %sum(y_age0))\n",
    "\n",
    "X_train0, X_test0, y_train0, y_test0 = train_test_split(X_age0, y_age0, test_size=0.2, stratify=y_age0, random_state=SEED)\n",
    "print(\"train0 : %d\" % sum(y_train0), \"test0 : %d\" % sum(y_test0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total cases = 60292\n",
      "total abnormal function of kidney = 2288\n",
      "train1 : 1830 test0 : 458\n"
     ]
    }
   ],
   "source": [
    "##age1 group\n",
    "X_age1 = df3[df3['level']==1]\n",
    "y_age1 = X_age1['eGFR_ab45']\n",
    "\n",
    "print(\"total cases = %d\" %X_age1.shape[0])\n",
    "print(\"total abnormal function of kidney = %d\" %sum(y_age1))\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X_age1, y_age1, test_size=0.2, stratify=y_age1, random_state=SEED)\n",
    "print(\"train1 : %d\" % sum(y_train1), \"test0 : %d\" % sum(y_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total cases = 20503\n",
      "total abnormal function of kidney = 3289\n",
      "train2 : 2631 test2 : 658\n"
     ]
    }
   ],
   "source": [
    "##age2 group\n",
    "X_age2 = df3[df3['level']==2]\n",
    "y_age2 = X_age2['eGFR_ab45']\n",
    "\n",
    "print(\"total cases = %d\" %X_age2.shape[0])\n",
    "print(\"total abnormal function of kidney = %d\" %sum(y_age2))\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_age2, y_age2, test_size=0.2, stratify=y_age2, random_state=SEED)\n",
    "print(\"train2 : %d\" % sum(y_train2), \"test2 : %d\" % sum(y_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total cases = 220020\n",
      "total abnormal function of kidney = 6416\n"
     ]
    }
   ],
   "source": [
    "##concat both trainset and testset\n",
    "X_train = pd.concat([X_train0, X_train1, X_train2])\n",
    "y_train = pd.concat([y_train0, y_train1, y_train2])\n",
    "\n",
    "X_test = pd.concat([X_test0, X_test1, X_test2])\n",
    "y_test = pd.concat([y_test0, y_test1, y_test2])\n",
    "\n",
    "print(\"total cases = %d\" % (X_train.shape[0] + X_test.shape[0]))\n",
    "print(\"total abnormal function of kidney = %d\" % (sum(y_train) + sum(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176015 train cases, 12 variables\n",
      "44005 test cases\n"
     ]
    }
   ],
   "source": [
    "X_train_features = X_train.loc[:, 'male':'leucocyte']\n",
    "\n",
    "print('%d train cases, %d variables' % (X_train_features.shape[0], X_train_features.shape[1]))\n",
    "print('%d test cases'%X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>he_uph</th>\n",
       "      <th>he_unitr</th>\n",
       "      <th>he_usg</th>\n",
       "      <th>he_upro</th>\n",
       "      <th>he_uglu</th>\n",
       "      <th>he_uket</th>\n",
       "      <th>he_ubil</th>\n",
       "      <th>he_ubld</th>\n",
       "      <th>he_uro</th>\n",
       "      <th>leucocyte</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>176015.000000</td>\n",
       "      <td>1.760150e+05</td>\n",
       "      <td>1.760150e+05</td>\n",
       "      <td>176015.000000</td>\n",
       "      <td>1.760150e+05</td>\n",
       "      <td>176015.000000</td>\n",
       "      <td>176015.000000</td>\n",
       "      <td>176015.000000</td>\n",
       "      <td>176015.000000</td>\n",
       "      <td>176015.000000</td>\n",
       "      <td>176015.000000</td>\n",
       "      <td>176015.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.428731</td>\n",
       "      <td>2.428557e-16</td>\n",
       "      <td>-2.570654e-16</td>\n",
       "      <td>0.020135</td>\n",
       "      <td>3.675389e-14</td>\n",
       "      <td>0.331608</td>\n",
       "      <td>0.233304</td>\n",
       "      <td>0.206147</td>\n",
       "      <td>0.038866</td>\n",
       "      <td>0.756186</td>\n",
       "      <td>0.167736</td>\n",
       "      <td>0.515882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.494896</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>0.140461</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>0.770634</td>\n",
       "      <td>0.887768</td>\n",
       "      <td>0.670891</td>\n",
       "      <td>0.321870</td>\n",
       "      <td>1.252175</td>\n",
       "      <td>0.559095</td>\n",
       "      <td>1.023959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.873179e+00</td>\n",
       "      <td>-1.437443e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.719457e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-7.814381e-01</td>\n",
       "      <td>-8.305855e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.088227e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.392376e-01</td>\n",
       "      <td>-2.237284e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.742333e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.956230e-01</td>\n",
       "      <td>9.899857e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.054634e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.071765e+00</td>\n",
       "      <td>3.417414e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.436693e+00</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                male           age        he_uph       he_unitr        he_usg  \\\n",
       "count  176015.000000  1.760150e+05  1.760150e+05  176015.000000  1.760150e+05   \n",
       "mean        0.428731  2.428557e-16 -2.570654e-16       0.020135  3.675389e-14   \n",
       "std         0.494896  1.000003e+00  1.000003e+00       0.140461  1.000003e+00   \n",
       "min         0.000000 -1.873179e+00 -1.437443e+00       0.000000 -1.719457e+00   \n",
       "25%         0.000000 -7.814381e-01 -8.305855e-01       0.000000 -1.088227e+00   \n",
       "50%         0.000000 -1.392376e-01 -2.237284e-01       0.000000  1.742333e-01   \n",
       "75%         1.000000  6.956230e-01  9.899857e-01       0.000000  8.054634e-01   \n",
       "max         1.000000  3.071765e+00  3.417414e+00       1.000000  1.436693e+00   \n",
       "\n",
       "             he_upro        he_uglu        he_uket        he_ubil  \\\n",
       "count  176015.000000  176015.000000  176015.000000  176015.000000   \n",
       "mean        0.331608       0.233304       0.206147       0.038866   \n",
       "std         0.770634       0.887768       0.670891       0.321870   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         5.000000       5.000000       5.000000       4.000000   \n",
       "\n",
       "             he_ubld         he_uro      leucocyte  \n",
       "count  176015.000000  176015.000000  176015.000000  \n",
       "mean        0.756186       0.167736       0.515882  \n",
       "std         1.252175       0.559095       1.023959  \n",
       "min         0.000000       0.000000       0.000000  \n",
       "25%         0.000000       0.000000       0.000000  \n",
       "50%         0.000000       0.000000       0.000000  \n",
       "75%         1.000000       0.000000       1.000000  \n",
       "max         5.000000       5.000000       4.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#standardization\n",
    "\n",
    "scaler = StandardScaler()\n",
    "std_cols=['age','he_uph','he_usg']\n",
    "std_df=X_train_features[std_cols]\n",
    "\n",
    "X_train_features[std_cols]=scaler.fit_transform(std_df)\n",
    "X_train_features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "counter = Counter(y_train)\n",
    "estimate = round(counter[0]/counter[1])\n",
    "step = round((estimate - 1)/3)\n",
    "estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danssa/anaconda3/envs/rapids-0.17/lib/python3.8/site-packages/distributed/node.py:151: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 40319 instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#https://dask-cuda.readthedocs.io/en/latest/quickstart.html\n",
    "\n",
    "from dask_cuda import LocalCUDACluster\n",
    "from dask.distributed import Client\n",
    "\n",
    "# Create a Dask Cluster with one worker per GPU\n",
    "cluster = LocalCUDACluster()\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 operators have been imported by TPOT.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Version 0.11.6.post3 of tpot is outdated. Version 0.11.7 was released Wednesday January 06, 2021.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be1b0dddb26f407895e77c8e85681596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/10100 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9540617390082469\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.6000000000000001, XGBClassifier__gamma=0.6000000000000001, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=3, XGBClassifier__min_child_weight=15, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=6, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=1.0, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 2 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9540617390082469\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.6000000000000001, XGBClassifier__gamma=0.6000000000000001, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=3, XGBClassifier__min_child_weight=15, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=6, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=1.0, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "\n",
      "Generation 3 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9540617390082469\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.6000000000000001, XGBClassifier__gamma=0.6000000000000001, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=3, XGBClassifier__min_child_weight=15, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0, XGBClassifier__reg_lambda=6, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=1.0, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 4 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9547002840874249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=4, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=1, XGBClassifier__reg_lambda=2, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.2, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "\n",
      "Generation 5 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9547002840874249\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=4, XGBClassifier__min_child_weight=20, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=1, XGBClassifier__reg_lambda=2, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.2, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "\n",
      "Generation 6 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9547038907620052\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.2000000000000002, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=4, XGBClassifier__min_child_weight=12, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.5, XGBClassifier__reg_lambda=6, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.2, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "\n",
      "Generation 7 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9547337784424718\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=4, XGBClassifier__min_child_weight=5, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=1, XGBClassifier__reg_lambda=2, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.2, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 8 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9547337784424718\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=4, XGBClassifier__min_child_weight=5, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=1, XGBClassifier__reg_lambda=2, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.2, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "\n",
      "Generation 9 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9547540812777372\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.0, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=4, XGBClassifier__min_child_weight=6, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=1, XGBClassifier__reg_lambda=2, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.2, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "\n",
      "Generation 10 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9547657606798869\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.4000000000000001, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=4, XGBClassifier__min_child_weight=4, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.5, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.2, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "\n",
      "Generation 11 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9547657606798869\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.4000000000000001, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=4, XGBClassifier__min_child_weight=4, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.5, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.2, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "\n",
      "Generation 12 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9547911887387646\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.8, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=4, XGBClassifier__min_child_weight=4, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.5, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.2, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "\n",
      "Generation 13 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9547911887387646\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.8, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=4, XGBClassifier__min_child_weight=4, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.5, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.2, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "\n",
      "Generation 14 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9547911887387646\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.8, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=4, XGBClassifier__min_child_weight=4, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.5, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.2, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "\n",
      "Generation 15 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9547912587233395\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=0.4, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=4, XGBClassifier__min_child_weight=4, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.25, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.2, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "\n",
      "Generation 16 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548139348315807\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=0.6000000000000001, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=4, XGBClassifier__min_child_weight=11, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=1, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.2, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "\n",
      "Generation 17 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548139348315807\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=0.6000000000000001, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=4, XGBClassifier__min_child_weight=11, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=1, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.2, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "\n",
      "Generation 18 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548139348315807\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=0.6000000000000001, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=4, XGBClassifier__min_child_weight=11, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=1, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.2, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "\n",
      "Generation 19 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548142738113011\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.6, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=3, XGBClassifier__min_child_weight=4, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.5, XGBClassifier__reg_lambda=4, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "\n",
      "Generation 20 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548142738113011\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.6, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=3, XGBClassifier__min_child_weight=4, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.5, XGBClassifier__reg_lambda=4, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 21 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548142738113011\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.6, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=3, XGBClassifier__min_child_weight=4, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.5, XGBClassifier__reg_lambda=4, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 22 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548167417563477\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.8, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=3, XGBClassifier__min_child_weight=1, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.25, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "\n",
      "Generation 23 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548167417563477\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.8, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=3, XGBClassifier__min_child_weight=1, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.25, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "\n",
      "Generation 24 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548357537161628\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=0.4, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=4, XGBClassifier__min_child_weight=11, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=1, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.2, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "\n",
      "Generation 25 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548357537161628\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=0.4, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=4, XGBClassifier__min_child_weight=11, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=1, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.2, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "\n",
      "Generation 26 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548357537161628\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=0.4, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=4, XGBClassifier__min_child_weight=11, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=1, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.2, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 27 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548357537161628\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=0.4, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=4, XGBClassifier__min_child_weight=11, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=1, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.2, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 28 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548357537161628\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=0.4, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=4, XGBClassifier__min_child_weight=11, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=1, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.2, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "\n",
      "Generation 29 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548357537161628\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=0.4, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=4, XGBClassifier__min_child_weight=11, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=1, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.2, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "\n",
      "Generation 30 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548357537161628\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=0.4, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=4, XGBClassifier__min_child_weight=11, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=1, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.2, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 31 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548357537161628\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=0.4, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=4, XGBClassifier__min_child_weight=11, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=1, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.2, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 32 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548357537161628\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=0.4, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=4, XGBClassifier__min_child_weight=11, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=1, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.2, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 33 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548357537161628\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=0.4, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=4, XGBClassifier__min_child_weight=11, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=1, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.2, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 34 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548357537161628\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=0.4, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=4, XGBClassifier__min_child_weight=11, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=1, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.2, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "\n",
      "Generation 35 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548357537161628\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=0.4, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=4, XGBClassifier__min_child_weight=11, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=1, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.2, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "\n",
      "Generation 36 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548357537161628\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=0.4, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=4, XGBClassifier__min_child_weight=11, XGBClassifier__n_estimators=500, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=1, XGBClassifier__reg_lambda=1, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.2, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 37 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548402462784085\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.2000000000000002, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=3, XGBClassifier__min_child_weight=2, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.5, XGBClassifier__reg_lambda=4, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 38 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548408211914182\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.8, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=3, XGBClassifier__min_child_weight=2, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.5, XGBClassifier__reg_lambda=4, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 39 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548408211914182\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.8, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=3, XGBClassifier__min_child_weight=2, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.5, XGBClassifier__reg_lambda=4, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 40 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548408211914182\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.8, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=3, XGBClassifier__min_child_weight=2, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.5, XGBClassifier__reg_lambda=4, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 41 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548408211914182\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.8, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=3, XGBClassifier__min_child_weight=2, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.5, XGBClassifier__reg_lambda=4, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "\n",
      "Generation 42 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548408211914182\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.8, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=3, XGBClassifier__min_child_weight=2, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.5, XGBClassifier__reg_lambda=4, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 43 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548410639712996\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.6, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=3, XGBClassifier__min_child_weight=2, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.5, XGBClassifier__reg_lambda=4, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 44 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548410639712996\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.6, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=3, XGBClassifier__min_child_weight=2, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.5, XGBClassifier__reg_lambda=4, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 45 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548410639712996\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.6, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=3, XGBClassifier__min_child_weight=2, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.5, XGBClassifier__reg_lambda=4, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 46 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548410639712996\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.6, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=3, XGBClassifier__min_child_weight=2, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.5, XGBClassifier__reg_lambda=4, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 47 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548410639712996\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.6, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=3, XGBClassifier__min_child_weight=2, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.5, XGBClassifier__reg_lambda=4, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 48 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548410639712996\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.6, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=3, XGBClassifier__min_child_weight=2, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.5, XGBClassifier__reg_lambda=4, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 49 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548410639712996\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.6, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=3, XGBClassifier__min_child_weight=2, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.5, XGBClassifier__reg_lambda=4, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 50 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548410639712996\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.6, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=3, XGBClassifier__min_child_weight=2, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.5, XGBClassifier__reg_lambda=4, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 51 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548410639712996\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.6, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=3, XGBClassifier__min_child_weight=2, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.5, XGBClassifier__reg_lambda=4, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 52 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548410639712996\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.6, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=3, XGBClassifier__min_child_weight=2, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.5, XGBClassifier__reg_lambda=4, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 53 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548410639712996\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.6, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=3, XGBClassifier__min_child_weight=2, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.5, XGBClassifier__reg_lambda=4, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 54 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548410639712996\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.6, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=3, XGBClassifier__min_child_weight=2, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.5, XGBClassifier__reg_lambda=4, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 55 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548410639712996\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.6, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=3, XGBClassifier__min_child_weight=2, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.5, XGBClassifier__reg_lambda=4, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 56 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548410639712996\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.6, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=3, XGBClassifier__min_child_weight=2, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.5, XGBClassifier__reg_lambda=4, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 57 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548410639712996\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.6, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=3, XGBClassifier__min_child_weight=2, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.5, XGBClassifier__reg_lambda=4, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 58 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548410639712996\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.6, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=3, XGBClassifier__min_child_weight=2, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.5, XGBClassifier__reg_lambda=4, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 59 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548410639712996\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.6, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=3, XGBClassifier__min_child_weight=2, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.5, XGBClassifier__reg_lambda=4, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 60 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548410639712996\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.6, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=3, XGBClassifier__min_child_weight=2, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.5, XGBClassifier__reg_lambda=4, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 61 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548410639712996\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.6, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=3, XGBClassifier__min_child_weight=2, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.5, XGBClassifier__reg_lambda=4, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 62 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548410639712996\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.6, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=3, XGBClassifier__min_child_weight=2, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.5, XGBClassifier__reg_lambda=4, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 63 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548410639712996\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.6, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=3, XGBClassifier__min_child_weight=2, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.5, XGBClassifier__reg_lambda=4, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 64 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548410639712996\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.6, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=3, XGBClassifier__min_child_weight=2, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.5, XGBClassifier__reg_lambda=4, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 65 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548410639712996\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.6, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=3, XGBClassifier__min_child_weight=2, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.5, XGBClassifier__reg_lambda=4, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 66 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548410639712996\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.6, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=3, XGBClassifier__min_child_weight=2, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.5, XGBClassifier__reg_lambda=4, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 67 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548410639712996\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.6, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=3, XGBClassifier__min_child_weight=2, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.5, XGBClassifier__reg_lambda=4, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 68 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548410639712996\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.6, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=3, XGBClassifier__min_child_weight=2, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.5, XGBClassifier__reg_lambda=4, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 69 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548410639712996\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.6, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=3, XGBClassifier__min_child_weight=2, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.5, XGBClassifier__reg_lambda=4, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 70 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548410639712996\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.6, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=3, XGBClassifier__min_child_weight=2, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.5, XGBClassifier__reg_lambda=4, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 71 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548410639712996\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.6, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=3, XGBClassifier__min_child_weight=2, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.5, XGBClassifier__reg_lambda=4, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 72 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548410639712996\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.6, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=3, XGBClassifier__min_child_weight=2, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.5, XGBClassifier__reg_lambda=4, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 73 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548410639712996\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.6, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=3, XGBClassifier__min_child_weight=2, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.5, XGBClassifier__reg_lambda=4, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 74 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548410639712996\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.6, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=3, XGBClassifier__min_child_weight=2, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.5, XGBClassifier__reg_lambda=4, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 75 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548410639712996\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.6, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=3, XGBClassifier__min_child_weight=2, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.5, XGBClassifier__reg_lambda=4, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 76 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548410639712996\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.6, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=3, XGBClassifier__min_child_weight=2, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.5, XGBClassifier__reg_lambda=4, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 77 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9548410639712996\tXGBClassifier(input_matrix, XGBClassifier__colsample_bytree=0.8000000000000002, XGBClassifier__gamma=1.6, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=3, XGBClassifier__min_child_weight=2, XGBClassifier__n_estimators=750, XGBClassifier__n_jobs=1, XGBClassifier__objective=binary:logistic, XGBClassifier__reg_alpha=0.5, XGBClassifier__reg_lambda=4, XGBClassifier__scale_pos_weight=33, XGBClassifier__subsample=0.4, XGBClassifier__tree_method=gpu_hist, XGBClassifier__verbosity=0)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n"
     ]
    }
   ],
   "source": [
    "classifier_config_dict = {\n",
    "\n",
    "    # xgboost tree method = gpu hist\n",
    "    \n",
    "    'xgboost.XGBClassifier': {\n",
    "        'n_estimators': [100, 250 ,500, 750, 1000],\n",
    "        'learning_rate': [1e-2, 1e-1, 0.3],\n",
    "        'max_depth': range(2, 11),\n",
    "        'min_child_weight': range(1, 21),\n",
    "        'gamma':np.arange(0, 2.01, 0.2),\n",
    "        'subsample': np.arange(0.2, 1.01, 0.2),\n",
    "        'colsample_bytree': np.arange(0.4,1.01,0.2),\n",
    "        \"reg_alpha\": [0, 0.25, 0.5, 0.75, 1],\n",
    "        \"reg_lambda\": [1, 2, 4, 6, 8],\n",
    "        'scale_pos_weight': [estimate],\n",
    "        'objective': ['binary:logistic'],\n",
    "        'tree_method' : ['gpu_hist'],\n",
    "        'n_jobs': [1],\n",
    "        'verbosity': [0]\n",
    "    },\n",
    "\n",
    "}\n",
    "\n",
    "tpot = TPOTClassifier(scoring=\"roc_auc\",\n",
    "                      cv=5,\n",
    "                      random_state=SEED,\n",
    "                      n_jobs=4,\n",
    "                      verbosity=3,\n",
    "                      generations=100,\n",
    "                      population_size=100,\n",
    "                      use_dask=True,\n",
    "                      warm_start=False,\n",
    "                      config_dict=classifier_config_dict,\n",
    "                      template='Classifier')\n",
    "\n",
    "training_features=X_train_features.copy(deep=True)\n",
    "tpot.fit(training_features, y_train)\n",
    "\n",
    "tpot.export('/home/danssa/proj_ua/paper_cha/CHA+SV/45model/chasv_45model.v1.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot.export('/home/danssa/proj_ua/paper_cha/CHA+SV/45model/chasv_45model.v1.py')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multi_gpu",
   "language": "python",
   "name": "rapids-0.17"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
